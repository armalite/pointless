# pointless

Pointless is the AI buddy that reads your Jira tickets and codebase, then pretends it knows how long it'll take - just like your team, but faster. 

## Status
 - WORK IN PROGRESS. 
 - This repo currently contains the project scaffold (CLI + FastAPI) and a deterministic placeholder estimator for smoke tests. 
 - The real product is the LLM-based estimator with progressive retrieval from Jira + GitHub.

## Features

- ğŸ¤– **AI-Powered Estimation** â€” Uses context-aware LLMs to size work (days/points).
- ğŸ” **Progressive Retrieval** â€” Pulls just-enough context from Jira + GitHub; expands only if confidence is low.
- ğŸ§­ **Plan-First Output** â€” Produces a concrete work plan (steps with effort hours) before sizing.
- ğŸ“ **Impacted Files** â€” Lists likely files/paths to touch so reviewers can sanity-check fast.
- ğŸ“Š **Confidence Metrics** â€” Tells you how wrong we might be (with ranges).
- â“ **Assumptions & Questions** â€” Surfaces unknowns that drive estimate variance.
- ğŸ·ï¸ **Complexity Assessment** â€” Tags tasks from â€œtrivialâ€ to â€œexpertâ€ (mostly expert).
- ğŸ“ **Detailed Reasoning** â€” Explains our wild guesses with pseudo-scientific justification.
- ğŸ”„ **Multiple Interfaces** â€” CLI for developers, REST API for integrations.
- ğŸ¯ **Jira Integration Ready** â€” Accepts Jira ticket IDs (because everything is in Jira).
- ğŸ“ **Write-Back to Jira (optional)** â€” Posts estimate, confidence, and assumptions to the ticket.
- ğŸ¯ **Calibration (later)** â€” Learns from past tickets to tighten ranges per team.
- ğŸ§© **Pluggable Models** â€” Bring your own LLM (OpenAI/Anthropic/Gemini), configurable context limits.
- ğŸ” **Local-First / Private** â€” Runs locally; easy to containerize for on-prem/VPC.
- ğŸ§ª **Deterministic Baseline Mode** â€” Heuristic stub for CI smoke tests while the LLM flow evolves.


## Install
```
git clone https://github.com/armalite/pointless.git
cd pointless
poetry install
```

## Configuration


### Heuristic
```bash
EEAI_ESTIMATOR=heuristic   # default for now; LLM path coming soon
```

### LLM
```bash
EEAI_JIRA_BASE_URL=...
EEAI_JIRA_TOKEN=...          # or OAuth later
EEAI_GH_TOKEN=...            # or GitHub App later
EEAI_MODEL_PROVIDER=openai   # provider selection
EEAI_OPENAI_API_KEY=...
EEAI_CONFIDENCE_THRESHOLD=0.7
EEAI_MAX_FILES=20
```
You can store these in a local .env (gitignored).


Roadmap (near-term)

 - LLM output schema & prompts (plan â†’ size â†’ confidence/assumptions/questions)
 - Progressive retrieval v1 (rank â†’ fetch snippets â†’ expand)
 - Jira & GitHub connectors (MCP or direct APIs)
 - Write-back to Jira (comment/fields)
 - Optional Docker/Compose; Helm later if useful


 ## License
 MIT