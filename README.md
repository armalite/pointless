# pointless
Pointless is the AI buddy that reads your Jira tickets and codebase, then pretends it knows how long it'll take - just like your team, but faster. 

## Status
 - WORK IN PROGRESS. 
 - This repo currently contains the project scaffold (CLI + FastAPI) and a deterministic placeholder estimator for smoke tests. 
 - The real product is the LLM-based estimator with progressive retrieval from Jira + GitHub.

## Why (Story) Pointless?
Estimating every task manually is calorie-counting peanuts. Pointless just does it for you: **plan â†’ effort â†’ confidence**. If someone needs story points, weâ€™ll garnish the plate.

## Features

- ğŸ¤– **AI-Powered Estimation** â€” Uses context-aware LLMs to size work (days/points).
- ğŸ” **Progressive Retrieval** â€” Pulls just-enough context from Jira + GitHub; expands only if confidence is low.
- ğŸ§­ **Plan-First Output** â€” Produces a concrete work plan (steps with effort hours) before sizing.
- ğŸ“ **Impacted Files** â€” Lists likely files/paths to touch so reviewers can sanity-check fast.
- ğŸ“Š **Confidence Metrics** â€” Tells you how wrong we might be (with ranges).
- â“ **Assumptions & Questions** â€” Surfaces unknowns that drive estimate variance.
- ğŸ·ï¸ **Complexity Assessment** â€” Tags tasks from â€œtrivialâ€ to â€œexpertâ€ (mostly expert).
- ğŸ“ **Detailed Reasoning** â€” Explains our wild guesses with pseudo-scientific justification.
- ğŸ”„ **Multiple Interfaces** â€” CLI for developers, REST API for integrations.
- ğŸ¯ **Jira Integration Ready** â€” Accepts Jira ticket IDs (because everything is in Jira).
- ğŸ“ **Write-Back to Jira (optional)** â€” Posts estimate, confidence, and assumptions to the ticket.
- ğŸ¯ Story Points (optional) â€” Output points alongside days/hours for teams that still need them.
- ğŸ¯ **Calibration (later)** â€” Learns from past tickets to tighten ranges per team.
- ğŸ§© **Pluggable Models** â€” Bring your own LLM (OpenAI/Anthropic/Gemini), configurable context limits.
- ğŸ” **Local-First / Private** â€” Runs locally; easy to containerize for on-prem/VPC.
- ğŸ§ª **Deterministic Baseline Mode** â€” Heuristic stub for CI smoke tests while the LLM flow evolves.


## Install
```
git clone https://github.com/armalite/pointless.git
cd pointless
poetry install
```

## Configuration


### Heuristic
```bash
POINTLESS_ESTIMATOR=heuristic   # default for now; LLM path coming soon
```

### LLM
```bash
POINTLESS_JIRA_BASE_URL=...
POINTLESS_JIRA_TOKEN=...          # or OAuth later
POINTLESS_GH_TOKEN=...            # or GitHub App later
POINTLESS_MODEL_PROVIDER=openai   # provider selection
POINTLESS_OPENAI_API_KEY=...
POINTLESS_CONFIDENCE_THRESHOLD=0.7
POINTLESS_MAX_FILES=20
```

### MCP (Model Context Protocol) Integration
```bash
POINTLESS_MCP_ENABLED=true                    # Enable MCP integration
POINTLESS_MCP_ATLASSIAN_SERVER_URL=...        # Atlassian MCP server URL
POINTLESS_MCP_ATLASSIAN_API_TOKEN=...         # Atlassian API token
POINTLESS_MCP_ATLASSIAN_EMAIL=...             # Atlassian account email
POINTLESS_MCP_TIMEOUT=30                      # MCP request timeout in seconds
```

You can store these in a local .env (gitignored).


## Quick Start

### CLI
Basic estimate:
```bash
poetry run pointless estimate \
  "Add client method to get all domain monitors" \
  -d "Expose GET /domains/{id}/monitors via sdk/client.py"
```

With tags (repeatable) and optional local repo path:
```bash
poetry run pointless estimate \
  "Add client method to get all domain monitors" \
  -d "Expose GET /domains/{id}/monitors via sdk/client.py" \
  -t urgent -t backend \
  -r ~/src/your-repo
```

With MCP integration for Jira ticket data:
```bash
poetry run pointless estimate \
  "Add client method to get all domain monitors" \
  -j PROJ-123 \
  --mcp
```

Show help / version: 
```bash
poetry run pointless --help
poetry run pointless version
```

Example output:
```bash
{
  "estimated_hours": 3.4,
  "complexity": "moderate",
  "confidence": 0.7,
  "reasoning": "Heuristic baseline only; final implementation will use progressive retrieval over Jira/GitHub and an LLM (planâ†’size) with confidence & assumptions.",
  "factors": ["Moderate description length", "Urgent tagâ€”risk of optimistic sizing"]
}
```

### API
Run the server locally:
```bash
poetry run uvicorn pointless.interfaces.api:app --host 0.0.0.0 --port 8080
```

Health check:
```bash
curl http://localhost:8080/healthz
```

Estimate (POST JSON):
```bash
curl -X POST http://localhost:8080/estimate \
  -H 'Content-Type: application/json' \
  -d '{
        "title": "Add client method to get all domain monitors",
        "description": "Expose GET /domains/{id}/monitors via sdk/client.py",
        "tags": ["urgent"]
      }'
```

With MCP integration:
```bash
curl -X POST http://localhost:8080/estimate \
  -H 'Content-Type: application/json' \
  -d '{
        "title": "Add client method to get all domain monitors",
        "description": "Expose GET /domains/{id}/monitors via sdk/client.py",
        "jira_ticket_id": "PROJ-123",
        "use_mcp": true,
        "tags": ["urgent"]
      }'
```

Tip: pretty-print with jq:
```bash
curl -s http://localhost:8080/healthz | jq

```

(The current responses come from the deterministic placeholder; the LLM + progressive retrieval flow will replace this output.)

## Roadmap (near-term)

 - LLM output schema & prompts (plan â†’ size â†’ confidence/assumptions/questions)
 - Progressive retrieval v1 (rank â†’ fetch snippets â†’ expand)
 - Jira & GitHub connectors (MCP or direct APIs)
 - Write-back to Jira (comment/fields)
 - Optional Docker/Compose; Helm later if useful


 ## License
 MIT